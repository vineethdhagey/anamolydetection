# Predictive Maintenance with NASA Turbofan FD002

A comprehensive, MLOps-ready pipeline for predictive maintenance using the NASA Turbofan Engine Degradation Simulation Dataset (FD002). This project implements real-time anomaly detection, Remaining Useful Life (RUL) prediction, and interactive visualization to predict engine failures before they occur.

## ğŸš€ Features

- **Data Ingestion**: Automated loading of FD002 dataset from Hugging Face Datasets
- **Preprocessing Pipeline**: Feature scaling, RUL calculation with capping, sequence generation for time-series modeling
- **Anomaly Detection**: Isolation Forest-based detection with visualization capabilities
- **RUL Prediction**: LSTM implementations (Keras and PyTorch) for regression-based RUL estimation
- **Real-time Simulation**: Streaming data simulation for real-time inference scenarios
- **Interactive Dashboard**: Streamlit-based web app with Plotly visualizations for live monitoring
- **MLOps-Ready**: Modular architecture, model serialization, logging, and configuration-driven workflows
- **Scalable Architecture**: Supports batch processing and streaming inference

## ğŸ“Š Dataset

**NASA Turbofan FD002** is a multivariate time-series dataset simulating turbofan engine degradation under variable operating conditions. Key characteristics:

- **Units**: 260 engines (train) + validation/test sets
- **Features**: 3 operational settings + 21 sensor measurements
- **Time Series**: Variable-length sequences per engine (cycles until failure)
- **Target**: Remaining Useful Life (RUL) prediction
- **Source**: [Hugging Face Datasets](https://huggingface.co/datasets/LucasThil/nasa_turbofan_degradation_FD002)

## ğŸ—ï¸ Architecture & Workflow

### Core Components

1. **Data Layer** (`src/utils.py`):
   - Dataset loading from Hugging Face
   - Streaming simulation generator

2. **Preprocessing Layer** (`src/preprocessing.py`):
   - RUL calculation with configurable capping (default: 125 cycles)
   - MinMax scaling for features and targets
   - Sequence creation for LSTM input (sliding windows)

3. **Anomaly Detection** (`src/anomaly_detection.py`):
   - Isolation Forest with contamination tuning
   - Visualization of anomalies over time cycles

4. **RUL Prediction** (`src/rul_prediction.py`):
   - PyTorch LSTM model with configurable layers
   - Training loop with validation
   - Keras alternative in training scripts



### Workflow Pipeline

```
Raw Data â†’ Preprocessing â†’ Feature Engineering â†’ Model Training â†’ Deployment
     â†“           â†“              â†“                    â†“              â†“
  FD002    Scaling/RUL    Sequences/         LSTM/Keras           Dashboard
  Load     Calculation   Normalization       Training             Inference
```




## Architecture Workflow

                                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                            â”‚  Data Ingestion          â”‚
                                                            â”‚ Load NASA FD002 (HF)     â”‚
                                                            â”‚ Train/val/test frames    â”‚
                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    â–¼
                                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                            â”‚    Preprocessing + Seq   â”‚
                                                            â”‚      MinMax scaling      â”‚
                                                            â”‚                          â”‚
                                                            â”‚ Sliding-window sequences â”‚
                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    â–¼
                                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                            â”‚  Anomaly Detection       â”‚
                                                            â”‚  Isolation Forest        â”‚
                                                            â”‚ Mark/visualize anomalies â”‚
                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    â–¼
                                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                            â”‚    Model Training        â”‚
                                                            â”‚        LSTM              â”‚
                                                            â”‚ Save models (.pt/.h5)    â”‚
                                                            â”‚ Save scalers (.pkl)      â”‚
                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    â–¼
                                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                            â”‚    Evaluation            â”‚
                                                            â”‚                          â”‚
                                                            â”‚ Compare Pred RUL vs True â”‚
                                                            â”‚ Plot predictions         â”‚
                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                    â–¼
                                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                            â”‚    Deployment            â”‚
                                                            â”‚ Batch + Streaming infer  â”‚
                                                            â”‚ Realtime sim + dashboard â”‚
                                                            â”‚ (Streamlit monitoring)   â”‚
                                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜





















## ğŸ“ Project Structure

```
predictive_maintenance/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Raw dataset storage (auto-downloaded)
â”‚   â””â”€â”€ processed/           # Preprocessed data (sequences, scaled features)
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ note.ipynb           # Jupyter notebook for prototyping and EDA
â”œâ”€â”€ src/                     # Core source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils.py             # Data loading and streaming utilities
â”‚   â”œâ”€â”€ preprocessing.py     # Feature engineering and sequence creation
â”‚   â”œâ”€â”€ anomaly_detection.py # Isolation Forest implementation
â”‚   â”œâ”€â”€ rul_prediction.py    # PyTorch LSTM model and training
â”‚   â””â”€â”€ evaluation.py        # Metrics and visualization functions
â”œâ”€â”€ scripts/                 # Executable scripts
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ train_model.py       # Keras LSTM training pipeline
â”‚   â”œâ”€â”€ evaluate_model.py    # Model evaluation on validation set
â”‚   â”œâ”€â”€ predict_rul.py       # Batch RUL prediction on validation data
â”‚   â””â”€â”€ simulate_stream.py   # Streaming data simulation
â”œâ”€â”€ dashboards/
â”‚   â””â”€â”€ app.py               # Streamlit dashboard for interactive monitoring
â”œâ”€â”€ models/                  # Saved models and scalers
â”‚   â”œâ”€â”€ rul_model.pt         # PyTorch LSTM model
â”‚   â”œâ”€â”€ lstm_fd002.h5        # Keras LSTM model
â”‚   â”œâ”€â”€ lstm_fd002_best.h5   # Best Keras model checkpoint
â”‚   â”œâ”€â”€ feature_scaler.pkl   # Feature scaler
â”‚   â”œâ”€â”€ rul_scaler.pkl       # Target scaler
â”‚   â””â”€â”€ *.pkl                # Additional scaler variants
â”œâ”€â”€ logs/                    # Training logs and runtime outputs
â”œâ”€â”€ config/                  # YAML/JSON configuration files (extensible)
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .gitignore               # Git ignore rules
â””â”€â”€ README.md                # This file
```

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8+
- pip package manager
- Virtual environment (recommended)

### Setup Steps

1. **Clone the repository**:
   ```bash
   git clone https://github.com/vineethdhagey/anamolydetection.git
   cd predictive_maintenance
   ```

2. **Create virtual environment**:
   ```bash
   python -m venv venv
   source venv/bin/activate  # On Windows: venv\Scripts\activate
   ```

3. **Install dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

4. **Verify installation**:
   ```bash
   python -c "import torch, pandas, sklearn; print('Dependencies installed successfully')"
   ```

## ğŸš€ Usage

### 1. Data Preparation
```bash
# Load and preprocess data (via notebook or scripts)
python -c "from src.utils import load_fd002_dataset; df = load_fd002_dataset('train')"
```

### 2. Model Training
```bash
# Train Keras LSTM model
python scripts/train_model.py

# Or use PyTorch (from notebook)
# Follow notebooks/note.ipynb for PyTorch training
```



### 3. Batch Prediction
```bash
# Predict RUL on validation data
python scripts/predict_rul.py
```

### 4. Streaming Simulation
```bash
# Simulate real-time data streaming
python scripts/simulate_stream.py
```

### 5. Launch Dashboard
```bash
# Start interactive dashboard
streamlit run dashboards/app.py
```

## ğŸ“ˆ Model Details

### LSTM Architecture
- **Input**: Sequences of 50 time cycles Ã— 24 features (3 settings + 21 sensors)
- **Layers**: 2 LSTM layers (128 â†’ 64 units) + Dense output
- **Regularization**: Dropout (0.2), Batch Normalization
- **Optimizer**: Adam (lr=0.001)
- **Loss**: MSE with MAE metric

### Training Configuration
- **Batch Size**: 64
- **Epochs**: 100 (with early stopping)
- **Validation Split**: 20%
- **Sequence Length**: 50 cycles
- **RUL Cap**: 125 cycles

### Evaluation Metrics
- **RMSE**: Root Mean Squared Error
- **MAE**: Mean Absolute Error
- **RÂ² Score**: Coefficient of determination

## ğŸ¯ Dashboard Features

The Streamlit dashboard provides:

- **Unit Selection**: Dropdown for engine unit selection
- **Sensor Visualization**: Time-series plots with anomaly markers
- **RUL Prediction**: Smoothed prediction curves
- **Interactive Controls**: Toggle anomaly detection and RUL prediction
- **Raw Data Viewer**: Expandable data table

### Dashboard Screenshots
<img width="1683" height="837" alt="rul prediction" src="https://github.com/user-attachments/assets/47c0aa27-b4b2-42e0-ae70-c4e7f050a849" />




<img width="1520" height="770" alt="rul-2" src="https://github.com/user-attachments/assets/9596e99a-f5d1-4442-9770-9c9ceae305c9" />

*Real-time monitoring interface showing sensor data, anomalies, and RUL predictions*

## ğŸ”§ Configuration

The project supports configuration-driven workflows. Add YAML/JSON files to `config/` for:

- Model hyperparameters
- Dataset parameters
- Training settings
- Evaluation thresholds

Example config structure:
```yaml
model:
  sequence_length: 50
  batch_size: 64
  epochs: 100
  learning_rate: 0.001

data:
  rul_cap: 125
  contamination: 0.01
```

## ğŸ“¦ Dependencies

Key packages (see `requirements.txt`):

- **Data Processing**: `pandas`, `numpy`
- **Machine Learning**: `scikit-learn`, `torch`, `tensorflow`
- **Visualization**: `matplotlib`, `plotly`
- **Data Loading**: `datasets` (Hugging Face)
- **Dashboard**: `streamlit`
- **Serialization**: `joblib`

## ğŸ§ª Testing & Validation

### Performance Validation
- Cross-validation on training set
- Real-time simulation testing

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open Pull Request




## ğŸ“ Contact

This project was developed by : **Vineeth Dhagey**,


For questions or collaborations, please open an issue or reach out to me.

---

**Note**: This project demonstrates end-to-end MLOps practices for predictive maintenance, suitable for production deployment with additional monitoring and CI/CD integration.
